{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d76e23-969c-4a8d-bc5e-336673dd0b25",
   "metadata": {},
   "source": [
    "# Ensemble of tree-based models\n",
    "\n",
    "## Part 2: boosting and gradient boosting\n",
    "\n",
    "<img src=\"../figures/scikit-learn-logo.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7092ed-55e4-415e-97f6-07410c9ec0d4",
   "metadata": {},
   "source": [
    "# Boosting for classification\n",
    "\n",
    "<img src=\"../figures/boosting0.svg\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43d7fd-a61d-4011-ada4-6c9cd6560339",
   "metadata": {},
   "source": [
    "# Boosting for classification\n",
    "\n",
    "<img src=\"../figures/boosting1.svg\" width=\"40%\">\n",
    "<img src=\"../figures/boosting_trees1.svg\" width=\"40%\">\n",
    "\n",
    "\n",
    "A first shallow tree starts to separate circles from squares.\n",
    "Mistakes done by this first tree model shall be corrected\n",
    "by a second tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fa9c1-7034-4e32-b23e-d7f264579bb6",
   "metadata": {},
   "source": [
    "# Boosting for classification\n",
    "\n",
    "<img src=\"../figures/boosting2.svg\" width=\"40%\">\n",
    "<img src=\"../figures/boosting_trees2.svg\" width=\"40%\">\n",
    "\n",
    "\n",
    "So now, the second tree refines the first tree.\n",
    "The final model is a weighted sum of these two trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d76536-d3ab-4086-8f9b-39e111c12a4d",
   "metadata": {},
   "source": [
    "# Boosting for classification\n",
    "\n",
    "<img src=\"../figures/boosting3.svg\" width=\"40%\">\n",
    "<img src=\"../figures/boosting_trees3.svg\" width=\"40%\">\n",
    "\n",
    "\n",
    "\n",
    "Ensembling via boosting makes it possible to progressively refine the\n",
    "predictions of the previous model.\n",
    "\n",
    "At each step we focus on mistakes of the previous model to correct them.\n",
    "\n",
    "Even if the first models are underfitting (shallow trees), adding more trees\n",
    "makes it possible to perfectly classify all the training set data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b91fec-9018-4cd4-b433-b43e8ce3ccf7",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter1.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16262f-4f75-4445-8c42-1243e81b43e1",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter_sized1.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e836f-eab2-49bb-b32c-e545d3b90590",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter_orange1.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217c199-1124-4aba-939f-7620d8d7f7b5",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter2.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6987f-0a1a-4766-a552-3b6932d0a101",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter_sized2.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f68f-fa3f-44df-9a0e-d1dc952b75a3",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter_orange2.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bf93a-3c72-4896-9ff7-9326afabfbde",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter3.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6f264-3e2e-4b3d-a9ba-7f0c758378ae",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter_sized3.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b414b-4cdb-4878-a0fb-bf2f8dbbba13",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter_orange3.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6971393d-f306-4163-895d-6877198b422e",
   "metadata": {},
   "source": [
    "# Boosting for regression\n",
    "\n",
    "<img src=\"../figures/boosting/boosting_iter4.svg\" width=\"95%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9222c-220a-431f-8f8b-11a00f445f0b",
   "metadata": {},
   "source": [
    "# Boosting vs Gradient Boosting\n",
    "\n",
    "**Traditional Boosting**\n",
    ".small[`sklearn.ensemble.AdaBoostClassifier`]\n",
    "- Mispredicted **samples are re-weighted** at each step\n",
    "- Can use any base model that accepts `sample_weight`\n",
    "\n",
    "--\n",
    "\n",
    "**Gradient Boosting**\n",
    ".small[`sklearn.ensemble.HistGradientBoostingClassifier`]\n",
    "- Each base model predicts the **negative error** of previous models\n",
    "- `sklearn` use decision trees as the base model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11661931-d0b5-451a-a914-359f72098e4b",
   "metadata": {},
   "source": [
    "In practice, gradient boosting is more flexible thanks to the use of cost\n",
    "functions and tend to exhibits better predictive performance than traditional\n",
    "boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b21e8d-fb6b-4dd8-b44e-67a21b655444",
   "metadata": {},
   "source": [
    "# Gradient Boosting and binned features\n",
    "\n",
    "- `sklearn.ensemble.GradientBoostingClassifier`\n",
    "  - Implementation of the traditional (exact) method\n",
    "  - Fine for small data sets\n",
    "  - Too slow for `n_samples` > 10,000\n",
    "\n",
    "--\n",
    "\n",
    "- `sklearn.ensemble.HistGradientBoostingClassifier`\n",
    "  - Discretize numerical features (256 levels)\n",
    "  - Efficient multi core implementation\n",
    "  - **Much, much faster** when `n_samples` is large\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34c925-a29d-47a5-aee8-043619d314b6",
   "metadata": {},
   "source": [
    "Like traditional decision trees `GradientBoostingClassifier` and\n",
    "`GradientBoostingRegressor` internally rely on sorting the features values\n",
    "which as an `n * log(n)` time complexity and is therefore not suitable for\n",
    "large training set.\n",
    "\n",
    "`HistGradientBoostingClassifier` and `HistGradientBoostingRegressor` use\n",
    "histograms to approximate feature sorting to find the best feature split\n",
    "thresholds and can therefore be trained efficiently on datasets with hundreds\n",
    "of features and tens of millions of data points.\n",
    "\n",
    "Furthermore they can benefit from running on machines with many CPU cores very\n",
    "efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac511a02-9b4c-43b6-9d31-53978ed41af5",
   "metadata": {},
   "source": [
    "# Take away\n",
    "\n",
    "**Bagging**  | **Boosting**\n",
    "------------ | -------------\n",
    "fit trees **independently** | fit trees **sequentially**\n",
    "each **deep tree overfits** | each **shallow tree underfits**\n",
    "averaging the tree predictions **reduces overfitting** | sequentially adding trees **reduces underfitting**\n",
    "\n",
    "**Gradient boosting** tends to perform slightly better than **bagging** and\n",
    "**random forest**. Furthermore, shallow trees predict faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
