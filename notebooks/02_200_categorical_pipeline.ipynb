{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e27b1ab",
   "metadata": {},
   "source": [
    "# Encoding of categorical variables\n",
    "\n",
    "In this notebook, we will present typical ways of dealing with\n",
    "**categorical variables** by encoding them, namely **ordinal encoding** and\n",
    "**one-hot encoding**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b56a3",
   "metadata": {},
   "source": [
    "Let's first load the entire adult dataset containing both numerical and\n",
    "categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a2fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "# drop the duplicated column `\"education-num\"` as stated in the first notebook\n",
    "adult_census = adult_census.drop(columns=\"education-num\")\n",
    "\n",
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "\n",
    "data = adult_census.drop(columns=[target_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0ffa6",
   "metadata": {},
   "source": [
    "\n",
    "## Identify categorical variables\n",
    "\n",
    "As we saw in the previous section, a numerical variable is a\n",
    "quantity represented by a real or integer number. These variables can be\n",
    "naturally handled by machine learning algorithms that are typically composed\n",
    "of a sequence of arithmetic instructions such as additions and\n",
    "multiplications.\n",
    "\n",
    "In contrast, categorical variables have discrete values, typically\n",
    "represented by string labels (but not only) taken from a finite list of\n",
    "possible choices. For instance, the variable `native-country` in our dataset\n",
    "is a categorical variable because it encodes the data using a finite list of\n",
    "possible countries (along with the `?` symbol when this information is\n",
    "missing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d060943d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "native-country\n",
       " ?                               857\n",
       " Cambodia                         28\n",
       " Canada                          182\n",
       " China                           122\n",
       " Columbia                         85\n",
       " Cuba                            138\n",
       " Dominican-Republic              103\n",
       " Ecuador                          45\n",
       " El-Salvador                     155\n",
       " England                         127\n",
       " France                           38\n",
       " Germany                         206\n",
       " Greece                           49\n",
       " Guatemala                        88\n",
       " Haiti                            75\n",
       " Holand-Netherlands                1\n",
       " Honduras                         20\n",
       " Hong                             30\n",
       " Hungary                          19\n",
       " India                           151\n",
       " Iran                             59\n",
       " Ireland                          37\n",
       " Italy                           105\n",
       " Jamaica                         106\n",
       " Japan                            92\n",
       " Laos                             23\n",
       " Mexico                          951\n",
       " Nicaragua                        49\n",
       " Outlying-US(Guam-USVI-etc)       23\n",
       " Peru                             46\n",
       " Philippines                     295\n",
       " Poland                           87\n",
       " Portugal                         67\n",
       " Puerto-Rico                     184\n",
       " Scotland                         21\n",
       " South                           115\n",
       " Taiwan                           65\n",
       " Thailand                         30\n",
       " Trinadad&Tobago                  27\n",
       " United-States                 43832\n",
       " Vietnam                          86\n",
       " Yugoslavia                       23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"native-country\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814af5c8",
   "metadata": {},
   "source": [
    "How can we easily recognize categorical columns among the dataset? Part of\n",
    "the answer lies in the columns' data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d85897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "education         object\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835109d6",
   "metadata": {},
   "source": [
    "If we look at the `\"native-country\"` column, we observe its data type is\n",
    "`object`, meaning it contains string values.\n",
    "\n",
    "## Select features based on their data type\n",
    "\n",
    "In the previous notebook, we manually defined the numerical columns. We could\n",
    "do a similar approach. Instead, we will use the scikit-learn helper function\n",
    "`make_column_selector`, which allows us to select columns based on\n",
    "their data type. We will illustrate how to use this helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7790ee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2093bc0-dac5-4d21-b517-7c4e14173fd1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8f6d8f8",
   "metadata": {},
   "source": [
    "Here, we created the selector by passing the data type to include; we then\n",
    "passed the input dataset to the selector object, which returned a list of\n",
    "column names that have the requested data type. We can now filter out the\n",
    "unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3205867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    workclass      education       marital-status          occupation  \\\n",
       "0     Private           11th        Never-married   Machine-op-inspct   \n",
       "1     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  native-country  \n",
       "0    Own-child   Black     Male   United-States  \n",
       "1      Husband   White     Male   United-States  \n",
       "2      Husband   White     Male   United-States  \n",
       "3      Husband   Black     Male   United-States  \n",
       "4    Own-child   White   Female   United-States  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical = data[categorical_columns]\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6a9aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is composed of 8 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset is composed of {data_categorical.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1f6d1",
   "metadata": {},
   "source": [
    "In the remainder of this section, we will present different strategies to\n",
    "encode categorical data into numerical data which can be used by a\n",
    "machine-learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b48cfe0",
   "metadata": {},
   "source": [
    "## Strategies to encode categories\n",
    "\n",
    "### Encoding ordinal categories\n",
    "\n",
    "The most intuitive strategy is to encode each category with a different\n",
    "number. The `OrdinalEncoder` will transform the data in such manner.\n",
    "We will start by encoding a single column to understand how the encoding\n",
    "works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acb00a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [11.],\n",
       "       [ 7.],\n",
       "       ...,\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "education_column = data_categorical[[\"education\"]]\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "education_encoded = encoder.fit_transform(education_column)\n",
    "education_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb50bf",
   "metadata": {},
   "source": [
    "We see that each category in `\"education\"` has been replaced by a numeric\n",
    "value. We could check the mapping between the categories and the numerical\n",
    "values by checking the fitted attribute `categories_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a82d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th',\n",
       "        ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate',\n",
       "        ' HS-grad', ' Masters', ' Preschool', ' Prof-school',\n",
       "        ' Some-college'], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982acec",
   "metadata": {},
   "source": [
    "Now, we can check the encoding applied on all categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a3d9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  1.,  4.,  7.,  3.,  2.,  1., 39.],\n",
       "       [ 4., 11.,  2.,  5.,  0.,  4.,  1., 39.],\n",
       "       [ 2.,  7.,  2., 11.,  0.,  4.,  1., 39.],\n",
       "       [ 4., 15.,  2.,  7.,  0.,  2.,  1., 39.],\n",
       "       [ 0., 15.,  4.,  0.,  3.,  4.,  0., 39.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b244c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset encoded contains 8 features\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The dataset encoded contains {data_encoded.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e08d7f",
   "metadata": {},
   "source": [
    "We see that the categories have been encoded for each feature (column)\n",
    "independently. We also note that the number of features before and after the\n",
    "encoding is the same.\n",
    "\n",
    "However, be careful when applying this encoding strategy:\n",
    "using this integer representation leads downstream predictive models\n",
    "to assume that the values are ordered (0 < 1 < 2 < 3... for instance).\n",
    "\n",
    "By default, `OrdinalEncoder` uses a lexicographical strategy to map string\n",
    "category labels to integers. This strategy is arbitrary and often\n",
    "meaningless. For instance, suppose the dataset has a categorical variable\n",
    "named `\"size\"` with categories such as \"S\", \"M\", \"L\", \"XL\". We would like the\n",
    "integer representation to respect the meaning of the sizes by mapping them to\n",
    "increasing integers such as `0, 1, 2, 3`.\n",
    "However, the lexicographical strategy used by default would map the labels\n",
    "\"S\", \"M\", \"L\", \"XL\" to 2, 1, 0, 3, by following the alphabetical order.\n",
    "\n",
    "The `OrdinalEncoder` class accepts a `categories` constructor argument to\n",
    "pass categories in the expected ordering explicitly. You can find more\n",
    "information in the\n",
    "[scikit-learn documentation](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)\n",
    "if needed.\n",
    "\n",
    "If a categorical variable does not carry any meaningful order information\n",
    "then this encoding might be misleading to downstream statistical models and\n",
    "you might consider using one-hot encoding instead (see below).\n",
    "\n",
    "### Encoding nominal categories (without assuming any order)\n",
    "\n",
    "`OneHotEncoder` is an alternative encoder that prevents the downstream\n",
    "models to make a false assumption about the ordering of categories. For a\n",
    "given feature, it will create as many new columns as there are possible\n",
    "categories. For a given sample, the value of the column corresponding to the\n",
    "category will be set to `1` while all the columns of the other categories\n",
    "will be set to `0`.\n",
    "\n",
    "We will start by encoding a single feature (e.g. `\"education\"`) to illustrate\n",
    "how the encoding works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20aba569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "education_encoded = encoder.fit_transform(education_column)\n",
    "education_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0ca4c1-4dbc-4391-a42a-9b99e7fe9bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msparse_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'numpy.float64'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_frequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_categories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Encode categorical features as a one-hot numeric array.\n",
       "\n",
       "The input to this transformer should be an array-like of integers or\n",
       "strings, denoting the values taken on by categorical (discrete) features.\n",
       "The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n",
       "encoding scheme. This creates a binary column for each category and\n",
       "returns a sparse matrix or dense array (depending on the ``sparse_output``\n",
       "parameter)\n",
       "\n",
       "By default, the encoder derives the categories based on the unique values\n",
       "in each feature. Alternatively, you can also specify the `categories`\n",
       "manually.\n",
       "\n",
       "This encoding is needed for feeding categorical data to many scikit-learn\n",
       "estimators, notably linear models and SVMs with the standard kernels.\n",
       "\n",
       "Note: a one-hot encoding of y labels should use a LabelBinarizer\n",
       "instead.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "categories : 'auto' or a list of array-like, default='auto'\n",
       "    Categories (unique values) per feature:\n",
       "\n",
       "    - 'auto' : Determine categories automatically from the training data.\n",
       "    - list : ``categories[i]`` holds the categories expected in the ith\n",
       "      column. The passed categories should not mix strings and numeric\n",
       "      values within a single feature, and should be sorted in case of\n",
       "      numeric values.\n",
       "\n",
       "    The used categories can be found in the ``categories_`` attribute.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "drop : {'first', 'if_binary'} or an array-like of shape (n_features,),             default=None\n",
       "    Specifies a methodology to use to drop one of the categories per\n",
       "    feature. This is useful in situations where perfectly collinear\n",
       "    features cause problems, such as when feeding the resulting data\n",
       "    into an unregularized linear regression model.\n",
       "\n",
       "    However, dropping one category breaks the symmetry of the original\n",
       "    representation and can therefore induce a bias in downstream models,\n",
       "    for instance for penalized linear classification or regression models.\n",
       "\n",
       "    - None : retain all features (the default).\n",
       "    - 'first' : drop the first category in each feature. If only one\n",
       "      category is present, the feature will be dropped entirely.\n",
       "    - 'if_binary' : drop the first category in each feature with two\n",
       "      categories. Features with 1 or more than 2 categories are\n",
       "      left intact.\n",
       "    - array : ``drop[i]`` is the category in feature ``X[:, i]`` that\n",
       "      should be dropped.\n",
       "\n",
       "    When `max_categories` or `min_frequency` is configured to group\n",
       "    infrequent categories, the dropping behavior is handled after the\n",
       "    grouping.\n",
       "\n",
       "    .. versionadded:: 0.21\n",
       "       The parameter `drop` was added in 0.21.\n",
       "\n",
       "    .. versionchanged:: 0.23\n",
       "       The option `drop='if_binary'` was added in 0.23.\n",
       "\n",
       "    .. versionchanged:: 1.1\n",
       "        Support for dropping infrequent categories.\n",
       "\n",
       "sparse : bool, default=True\n",
       "    Will return sparse matrix if set True else will return an array.\n",
       "\n",
       "    .. deprecated:: 1.2\n",
       "       `sparse` is deprecated in 1.2 and will be removed in 1.4. Use\n",
       "       `sparse_output` instead.\n",
       "\n",
       "sparse_output : bool, default=True\n",
       "    Will return sparse matrix if set True else will return an array.\n",
       "\n",
       "    .. versionadded:: 1.2\n",
       "       `sparse` was renamed to `sparse_output`\n",
       "\n",
       "dtype : number type, default=float\n",
       "    Desired dtype of output.\n",
       "\n",
       "handle_unknown : {'error', 'ignore', 'infrequent_if_exist'},                      default='error'\n",
       "    Specifies the way unknown categories are handled during :meth:`transform`.\n",
       "\n",
       "    - 'error' : Raise an error if an unknown category is present during transform.\n",
       "    - 'ignore' : When an unknown category is encountered during\n",
       "      transform, the resulting one-hot encoded columns for this feature\n",
       "      will be all zeros. In the inverse transform, an unknown category\n",
       "      will be denoted as None.\n",
       "    - 'infrequent_if_exist' : When an unknown category is encountered\n",
       "      during transform, the resulting one-hot encoded columns for this\n",
       "      feature will map to the infrequent category if it exists. The\n",
       "      infrequent category will be mapped to the last position in the\n",
       "      encoding. During inverse transform, an unknown category will be\n",
       "      mapped to the category denoted `'infrequent'` if it exists. If the\n",
       "      `'infrequent'` category does not exist, then :meth:`transform` and\n",
       "      :meth:`inverse_transform` will handle an unknown category as with\n",
       "      `handle_unknown='ignore'`. Infrequent categories exist based on\n",
       "      `min_frequency` and `max_categories`. Read more in the\n",
       "      :ref:`User Guide <one_hot_encoder_infrequent_categories>`.\n",
       "\n",
       "    .. versionchanged:: 1.1\n",
       "        `'infrequent_if_exist'` was added to automatically handle unknown\n",
       "        categories and infrequent categories.\n",
       "\n",
       "min_frequency : int or float, default=None\n",
       "    Specifies the minimum frequency below which a category will be\n",
       "    considered infrequent.\n",
       "\n",
       "    - If `int`, categories with a smaller cardinality will be considered\n",
       "      infrequent.\n",
       "\n",
       "    - If `float`, categories with a smaller cardinality than\n",
       "      `min_frequency * n_samples`  will be considered infrequent.\n",
       "\n",
       "    .. versionadded:: 1.1\n",
       "        Read more in the :ref:`User Guide <one_hot_encoder_infrequent_categories>`.\n",
       "\n",
       "max_categories : int, default=None\n",
       "    Specifies an upper limit to the number of output features for each input\n",
       "    feature when considering infrequent categories. If there are infrequent\n",
       "    categories, `max_categories` includes the category representing the\n",
       "    infrequent categories along with the frequent categories. If `None`,\n",
       "    there is no limit to the number of output features.\n",
       "\n",
       "    .. versionadded:: 1.1\n",
       "        Read more in the :ref:`User Guide <one_hot_encoder_infrequent_categories>`.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "categories_ : list of arrays\n",
       "    The categories of each feature determined during fitting\n",
       "    (in order of the features in X and corresponding with the output\n",
       "    of ``transform``). This includes the category specified in ``drop``\n",
       "    (if any).\n",
       "\n",
       "drop_idx_ : array of shape (n_features,)\n",
       "    - ``drop_idx_[i]`` is the index in ``categories_[i]`` of the category\n",
       "      to be dropped for each feature.\n",
       "    - ``drop_idx_[i] = None`` if no category is to be dropped from the\n",
       "      feature with index ``i``, e.g. when `drop='if_binary'` and the\n",
       "      feature isn't binary.\n",
       "    - ``drop_idx_ = None`` if all the transformed features will be\n",
       "      retained.\n",
       "\n",
       "    If infrequent categories are enabled by setting `min_frequency` or\n",
       "    `max_categories` to a non-default value and `drop_idx[i]` corresponds\n",
       "    to a infrequent category, then the entire infrequent category is\n",
       "    dropped.\n",
       "\n",
       "    .. versionchanged:: 0.23\n",
       "       Added the possibility to contain `None` values.\n",
       "\n",
       "infrequent_categories_ : list of ndarray\n",
       "    Defined only if infrequent categories are enabled by setting\n",
       "    `min_frequency` or `max_categories` to a non-default value.\n",
       "    `infrequent_categories_[i]` are the infrequent categories for feature\n",
       "    `i`. If the feature `i` has no infrequent categories\n",
       "    `infrequent_categories_[i]` is None.\n",
       "\n",
       "    .. versionadded:: 1.1\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "OrdinalEncoder : Performs an ordinal (integer)\n",
       "  encoding of the categorical features.\n",
       "sklearn.feature_extraction.DictVectorizer : Performs a one-hot encoding of\n",
       "  dictionary items (also handles string-valued features).\n",
       "sklearn.feature_extraction.FeatureHasher : Performs an approximate one-hot\n",
       "  encoding of dictionary items or strings.\n",
       "LabelBinarizer : Binarizes labels in a one-vs-all\n",
       "  fashion.\n",
       "MultiLabelBinarizer : Transforms between iterable of\n",
       "  iterables and a multilabel format, e.g. a (samples x classes) binary\n",
       "  matrix indicating the presence of a class label.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Given a dataset with two features, we let the encoder find the unique\n",
       "values per feature and transform the data to a binary one-hot encoding.\n",
       "\n",
       ">>> from sklearn.preprocessing import OneHotEncoder\n",
       "\n",
       "One can discard categories not seen during `fit`:\n",
       "\n",
       ">>> enc = OneHotEncoder(handle_unknown='ignore')\n",
       ">>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
       ">>> enc.fit(X)\n",
       "OneHotEncoder(handle_unknown='ignore')\n",
       ">>> enc.categories_\n",
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
       ">>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n",
       "array([[1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])\n",
       ">>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
       "array([['Male', 1],\n",
       "       [None, 2]], dtype=object)\n",
       ">>> enc.get_feature_names_out(['gender', 'group'])\n",
       "array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'], ...)\n",
       "\n",
       "One can always drop the first column for each feature:\n",
       "\n",
       ">>> drop_enc = OneHotEncoder(drop='first').fit(X)\n",
       ">>> drop_enc.categories_\n",
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
       ">>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
       "array([[0., 0., 0.],\n",
       "       [1., 1., 0.]])\n",
       "\n",
       "Or drop a column for feature only having 2 categories:\n",
       "\n",
       ">>> drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)\n",
       ">>> drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 1., 0.]])\n",
       "\n",
       "Infrequent categories are enabled by setting `max_categories` or `min_frequency`.\n",
       "\n",
       ">>> import numpy as np\n",
       ">>> X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3], dtype=object).T\n",
       ">>> ohe = OneHotEncoder(max_categories=3, sparse_output=False).fit(X)\n",
       ">>> ohe.infrequent_categories_\n",
       "[array(['a', 'd'], dtype=object)]\n",
       ">>> ohe.transform([[\"a\"], [\"b\"]])\n",
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.]])\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OneHotEncoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3625462",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p><tt class=\"docutils literal\">sparse_output=False</tt> is used in the <tt class=\"docutils literal\">OneHotEncoder</tt> for didactic purposes, namely\n",
    "easier visualization of the data.</p>\n",
    "<p class=\"last\">Sparse matrices are efficient data structures when most of your matrix\n",
    "elements are zero. They won't be covered in detail in this course. If you\n",
    "want more details about them, you can look at\n",
    "<a class=\"reference external\" href=\"https://scipy-lectures.org/advanced/scipy_sparse/introduction.html#why-sparse-matrices\">this</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ca012",
   "metadata": {},
   "source": [
    "We see that encoding a single feature will give a NumPy array full of zeros\n",
    "and ones. We can get a better understanding using the associated feature\n",
    "names resulting from the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573e00ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education_ 10th</th>\n",
       "      <th>education_ 11th</th>\n",
       "      <th>education_ 12th</th>\n",
       "      <th>education_ 1st-4th</th>\n",
       "      <th>education_ 5th-6th</th>\n",
       "      <th>education_ 7th-8th</th>\n",
       "      <th>education_ 9th</th>\n",
       "      <th>education_ Assoc-acdm</th>\n",
       "      <th>education_ Assoc-voc</th>\n",
       "      <th>education_ Bachelors</th>\n",
       "      <th>education_ Doctorate</th>\n",
       "      <th>education_ HS-grad</th>\n",
       "      <th>education_ Masters</th>\n",
       "      <th>education_ Preschool</th>\n",
       "      <th>education_ Prof-school</th>\n",
       "      <th>education_ Some-college</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       education_ 10th  education_ 11th  education_ 12th  education_ 1st-4th  \\\n",
       "0                  0.0              1.0              0.0                 0.0   \n",
       "1                  0.0              0.0              0.0                 0.0   \n",
       "2                  0.0              0.0              0.0                 0.0   \n",
       "3                  0.0              0.0              0.0                 0.0   \n",
       "4                  0.0              0.0              0.0                 0.0   \n",
       "...                ...              ...              ...                 ...   \n",
       "48837              0.0              0.0              0.0                 0.0   \n",
       "48838              0.0              0.0              0.0                 0.0   \n",
       "48839              0.0              0.0              0.0                 0.0   \n",
       "48840              0.0              0.0              0.0                 0.0   \n",
       "48841              0.0              0.0              0.0                 0.0   \n",
       "\n",
       "       education_ 5th-6th  education_ 7th-8th  education_ 9th  \\\n",
       "0                     0.0                 0.0             0.0   \n",
       "1                     0.0                 0.0             0.0   \n",
       "2                     0.0                 0.0             0.0   \n",
       "3                     0.0                 0.0             0.0   \n",
       "4                     0.0                 0.0             0.0   \n",
       "...                   ...                 ...             ...   \n",
       "48837                 0.0                 0.0             0.0   \n",
       "48838                 0.0                 0.0             0.0   \n",
       "48839                 0.0                 0.0             0.0   \n",
       "48840                 0.0                 0.0             0.0   \n",
       "48841                 0.0                 0.0             0.0   \n",
       "\n",
       "       education_ Assoc-acdm  education_ Assoc-voc  education_ Bachelors  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   0.0                   0.0   \n",
       "2                        1.0                   0.0                   0.0   \n",
       "3                        0.0                   0.0                   0.0   \n",
       "4                        0.0                   0.0                   0.0   \n",
       "...                      ...                   ...                   ...   \n",
       "48837                    1.0                   0.0                   0.0   \n",
       "48838                    0.0                   0.0                   0.0   \n",
       "48839                    0.0                   0.0                   0.0   \n",
       "48840                    0.0                   0.0                   0.0   \n",
       "48841                    0.0                   0.0                   0.0   \n",
       "\n",
       "       education_ Doctorate  education_ HS-grad  education_ Masters  \\\n",
       "0                       0.0                 0.0                 0.0   \n",
       "1                       0.0                 1.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "...                     ...                 ...                 ...   \n",
       "48837                   0.0                 0.0                 0.0   \n",
       "48838                   0.0                 1.0                 0.0   \n",
       "48839                   0.0                 1.0                 0.0   \n",
       "48840                   0.0                 1.0                 0.0   \n",
       "48841                   0.0                 1.0                 0.0   \n",
       "\n",
       "       education_ Preschool  education_ Prof-school  education_ Some-college  \n",
       "0                       0.0                     0.0                      0.0  \n",
       "1                       0.0                     0.0                      0.0  \n",
       "2                       0.0                     0.0                      0.0  \n",
       "3                       0.0                     0.0                      1.0  \n",
       "4                       0.0                     0.0                      1.0  \n",
       "...                     ...                     ...                      ...  \n",
       "48837                   0.0                     0.0                      0.0  \n",
       "48838                   0.0                     0.0                      0.0  \n",
       "48839                   0.0                     0.0                      0.0  \n",
       "48840                   0.0                     0.0                      0.0  \n",
       "48841                   0.0                     0.0                      0.0  \n",
       "\n",
       "[48842 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = encoder.get_feature_names_out(input_features=[\"education\"])\n",
    "education_encoded = pd.DataFrame(education_encoded, columns=feature_names)\n",
    "education_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32bdb178-b800-4fa0-afe7-ea2ad1badbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['education_ 10th', 'education_ 11th', 'education_ 12th',\n",
       "       'education_ 1st-4th', 'education_ 5th-6th', 'education_ 7th-8th',\n",
       "       'education_ 9th', 'education_ Assoc-acdm', 'education_ Assoc-voc',\n",
       "       'education_ Bachelors', 'education_ Doctorate',\n",
       "       'education_ HS-grad', 'education_ Masters', 'education_ Preschool',\n",
       "       'education_ Prof-school', 'education_ Some-college'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f1d54",
   "metadata": {},
   "source": [
    "As we can see, each category (unique value) became a column; the encoding\n",
    "returned, for each sample, a 1 to specify which category it belongs to.\n",
    "\n",
    "Let's apply this encoding on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67a96962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is composed of 8 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    workclass      education       marital-status          occupation  \\\n",
       "0     Private           11th        Never-married   Machine-op-inspct   \n",
       "1     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  native-country  \n",
       "0    Own-child   Black     Male   United-States  \n",
       "1      Husband   White     Male   United-States  \n",
       "2      Husband   White     Male   United-States  \n",
       "3      Husband   Black     Male   United-States  \n",
       "4    Own-child   White   Female   United-States  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"The dataset is composed of {data_categorical.shape[1]} features\")\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00585308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea10426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoded dataset contains 102 features\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The encoded dataset contains {data_encoded.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc8204",
   "metadata": {},
   "source": [
    "Let's wrap this NumPy array in a dataframe with informative column names as\n",
    "provided by the encoder object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8955935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>education_ 10th</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0           0.0                     0.0                   0.0   \n",
       "1           0.0                     0.0                   0.0   \n",
       "2           0.0                     0.0                   1.0   \n",
       "3           0.0                     0.0                   0.0   \n",
       "4           1.0                     0.0                   0.0   \n",
       "\n",
       "   workclass_ Never-worked  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                      0.0                 1.0                      0.0   \n",
       "1                      0.0                 1.0                      0.0   \n",
       "2                      0.0                 0.0                      0.0   \n",
       "3                      0.0                 1.0                      0.0   \n",
       "4                      0.0                 0.0                      0.0   \n",
       "\n",
       "   workclass_ Self-emp-not-inc  workclass_ State-gov  workclass_ Without-pay  \\\n",
       "0                          0.0                   0.0                     0.0   \n",
       "1                          0.0                   0.0                     0.0   \n",
       "2                          0.0                   0.0                     0.0   \n",
       "3                          0.0                   0.0                     0.0   \n",
       "4                          0.0                   0.0                     0.0   \n",
       "\n",
       "   education_ 10th  ...  native-country_ Portugal  \\\n",
       "0              0.0  ...                       0.0   \n",
       "1              0.0  ...                       0.0   \n",
       "2              0.0  ...                       0.0   \n",
       "3              0.0  ...                       0.0   \n",
       "4              0.0  ...                       0.0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    0.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     0.0                       0.0   \n",
       "4                    0.0                     0.0                       0.0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                              0.0                            1.0   \n",
       "1                              0.0                            1.0   \n",
       "2                              0.0                            1.0   \n",
       "3                              0.0                            1.0   \n",
       "4                              0.0                            1.0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                      0.0                         0.0  \n",
       "1                      0.0                         0.0  \n",
       "2                      0.0                         0.0  \n",
       "3                      0.0                         0.0  \n",
       "4                      0.0                         0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_encoded = encoder.get_feature_names_out(data_categorical.columns)\n",
    "pd.DataFrame(data_encoded, columns=columns_encoded).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ef6aa",
   "metadata": {},
   "source": [
    "Look at how the `\"workclass\"` variable of the 3 first records has been\n",
    "encoded and compare this to the original string representation.\n",
    "\n",
    "The number of features after the encoding is more than 10 times larger than\n",
    "in the original data because some variables such as `occupation` and\n",
    "`native-country` have many possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ce702",
   "metadata": {},
   "source": [
    "### Choosing an encoding strategy\n",
    "\n",
    "Choosing an encoding strategy will depend on the underlying models and the\n",
    "type of categories (i.e. ordinal vs. nominal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef18f3",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">In general <tt class=\"docutils literal\">OneHotEncoder</tt> is the encoding strategy used when the\n",
    "downstream models are <strong>linear models</strong> while <tt class=\"docutils literal\">OrdinalEncoder</tt> is often a\n",
    "good strategy with <strong>tree-based models</strong>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dfd721",
   "metadata": {},
   "source": [
    "\n",
    "Using an `OrdinalEncoder` will output ordinal categories. This means\n",
    "that there is an order in the resulting categories (e.g. `0 < 1 < 2`). The\n",
    "impact of violating this ordering assumption is really dependent on the\n",
    "downstream models. Linear models will be impacted by misordered categories\n",
    "while tree-based models will not.\n",
    "\n",
    "You can still use an `OrdinalEncoder` with linear models but you need to be\n",
    "sure that:\n",
    "- the original categories (before encoding) have an ordering;\n",
    "- the encoded categories follow the same ordering than the original\n",
    "  categories.\n",
    "The **next exercise** highlights the issue of misusing `OrdinalEncoder` with\n",
    "a linear model.\n",
    "\n",
    "One-hot encoding categorical variables with high cardinality can cause \n",
    "computational inefficiency in tree-based models. Because of this, it is not recommended\n",
    "to use `OneHotEncoder` in such cases even if the original categories do not \n",
    "have a given order. We will show this in the **final exercise** of this sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cb274",
   "metadata": {},
   "source": [
    "## Evaluate our predictive pipeline\n",
    "\n",
    "We can now integrate this encoder inside a machine learning pipeline like we\n",
    "did with numerical data: let's train a linear classifier on the encoded data\n",
    "and check the generalization performance of this machine learning pipeline using\n",
    "cross-validation.\n",
    "\n",
    "Before we create the pipeline, we have to linger on the `native-country`.\n",
    "Let's recall some statistics regarding this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9798d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "native-country\n",
       " United-States                 43832\n",
       " Mexico                          951\n",
       " ?                               857\n",
       " Philippines                     295\n",
       " Germany                         206\n",
       " Puerto-Rico                     184\n",
       " Canada                          182\n",
       " El-Salvador                     155\n",
       " India                           151\n",
       " Cuba                            138\n",
       " England                         127\n",
       " China                           122\n",
       " South                           115\n",
       " Jamaica                         106\n",
       " Italy                           105\n",
       " Dominican-Republic              103\n",
       " Japan                            92\n",
       " Guatemala                        88\n",
       " Poland                           87\n",
       " Vietnam                          86\n",
       " Columbia                         85\n",
       " Haiti                            75\n",
       " Portugal                         67\n",
       " Taiwan                           65\n",
       " Iran                             59\n",
       " Greece                           49\n",
       " Nicaragua                        49\n",
       " Peru                             46\n",
       " Ecuador                          45\n",
       " France                           38\n",
       " Ireland                          37\n",
       " Hong                             30\n",
       " Thailand                         30\n",
       " Cambodia                         28\n",
       " Trinadad&Tobago                  27\n",
       " Laos                             23\n",
       " Yugoslavia                       23\n",
       " Outlying-US(Guam-USVI-etc)       23\n",
       " Scotland                         21\n",
       " Honduras                         20\n",
       " Hungary                          19\n",
       " Holand-Netherlands                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"native-country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52070f06",
   "metadata": {},
   "source": [
    "We see that the `Holand-Netherlands` category is occurring rarely. This will\n",
    "be a problem during cross-validation: if the sample ends up in the test set\n",
    "during splitting then the classifier would not have seen the category during\n",
    "training and will not be able to encode it.\n",
    "\n",
    "In scikit-learn, there are two solutions to bypass this issue:\n",
    "\n",
    "* list all the possible categories and provide it to the encoder via the\n",
    "  keyword argument `categories`;\n",
    "* use the parameter `handle_unknown`, i.e. if an unknown category is encountered\n",
    "  during transform, the resulting one-hot encoded columns for this feature will\n",
    "  be all zeros. \n",
    "\n",
    "Here, we will use the latter solution for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218802d",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">Be aware the <tt class=\"docutils literal\">OrdinalEncoder</tt> exposes as well a parameter\n",
    "<tt class=\"docutils literal\">handle_unknown</tt>. It can be set to <tt class=\"docutils literal\">use_encoded_value</tt>. If that option is chosen,\n",
    "you can define a fixed value to which all unknowns will be set to during\n",
    "<tt class=\"docutils literal\">transform</tt>. For example,\n",
    "<tt class=\"docutils literal\"><span class=\"pre\">OrdinalEncoder(handle_unknown='use_encoded_value',</span> unknown_value=42)</tt>\n",
    "will set all values encountered during <tt class=\"docutils literal\">transform</tt> to <tt class=\"docutils literal\">42</tt> which are not part of\n",
    "the data encountered during the <tt class=\"docutils literal\">fit</tt> call.\n",
    "You are going to use these parameters in the next exercise.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de859a32",
   "metadata": {},
   "source": [
    "We can now create our machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcdd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"), LogisticRegression(max_iter=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88645b8",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">Here, we need to increase the maximum number of iterations to obtain a fully\n",
    "converged <tt class=\"docutils literal\">LogisticRegression</tt> and silence a <tt class=\"docutils literal\">ConvergenceWarning</tt>. Contrary\n",
    "to the numerical features, the one-hot encoded categorical features are all\n",
    "on the same scale (values are 0 or 1), so they would not benefit from\n",
    "scaling. In this case, increasing <tt class=\"docutils literal\">max_iter</tt> is the right thing to do.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0cc71",
   "metadata": {},
   "source": [
    "Finally, we can check the model's generalization performance only using the\n",
    "categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "667cb126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.77416301, 0.78002167, 0.73597336, 0.74399972, 0.83095217]),\n",
       " 'score_time': array([0.03298712, 0.02597404, 0.03199887, 0.02703094, 0.03004384]),\n",
       " 'test_score': array([0.83222438, 0.83560242, 0.82872645, 0.83312858, 0.83466421])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(model, data_categorical, target)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeebd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.833 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "print(f\"The accuracy is: {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31588e9",
   "metadata": {},
   "source": [
    "As you can see, this representation of the categorical variables is\n",
    "slightly more predictive of the revenue than the numerical variables\n",
    "that we used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc0a28",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook we have:\n",
    "* seen two common strategies for encoding categorical features: **ordinal\n",
    "  encoding** and **one-hot encoding**;\n",
    "* used a **pipeline** to use a **one-hot encoder** before fitting a logistic\n",
    "  regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb5a213d-db18-45ed-9c4a-6027f6bff22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workclass', 'education', 'marital-status', 'occupation',\n",
       "       'relationship', 'race', 'sex', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1dfea2-7efb-43e6-bd4f-e4f98e070d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
